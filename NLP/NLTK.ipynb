{
  "cells": [
    {
      "metadata": {
        "_uuid": "e12eb84c9c6defa600b45539d534f88f6bac0809"
      },
      "cell_type": "markdown",
      "source": "  **IMPORTING LIBRARIES**"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#import libraries\nimport nltk\nfrom nltk.corpus import stopwords#for stopwords\nfrom nltk.tokenize import word_tokenize#for tokenizing words\nfrom nltk.tokenize import sent_tokenize#sentence tokenizer\nfrom nltk import ne_chunk, pos_tag\nimport pandas as pd\nimport numpy as np\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd65e2700aabb5161bb9efde36be60443ded3317",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#load data\ntrain_data=pd.read_csv(\"../input/train.csv\")\n#test_data=pd.read_csv(\"../input/test.csv\")\nx=train_data.iloc[:,1].values\ncomment=np.array2string(x)\nprint(comment)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "c5da9af4c5bb3023daad451ee0ad12423abb944f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#removing unncessary punction marks from text\nfrom nltk.tokenize import RegexpTokenizer\ntokenizer=RegexpTokenizer(r'\\w+')\ncomment1=tokenizer.tokenize(comment)\nprint(comment1)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "adb6274a3a179557f5e458f72f77a121ccd11526",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#---------------------TEXT PRE PROCESSING-------------------------------------\n\n#STEP 1:NOISE REMOVAL-USING STOPWORDS\n#removing unwanted words for analysing-tokenizing and then applying stopwords\ncomment_1=\" \".join(str(e) for e in comment1)\nword=word_tokenize(comment_1)\nfiltered_comment=[]\nstop_words=set(stopwords.words(\"english\"))\n#print(stop_words)\nfor w in word:\n    if w not in stop_words:\n       filtered_comment.append(w)    \nprint(len(filtered_comment))\ncomment2= \" \".join(str(e) for e in filtered_comment) #converting list to string\nprint(comment2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2323d92e1b0c7a3da0e6b21b145eead4b7d36aa5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sent_tokenizer=sent_tokenize(comment)\nprint(sent_tokenizer)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#----------------TEXT TO FEATURES---------------------------------------------\n#STEP 2:POS TAGGING\n\nprint(pos_tag(word))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "59ebd164b4e51fca2628dfdfb23b030c1fffd428",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#analsing name entities:PERSON,ORGANIZATION AND LOCATION MENTIONED\ndef entities():\n    return ne_chunk(pos_tag(word))\ntree=entities()\ntree.pprint()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}