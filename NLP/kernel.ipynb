{
  "cells": [
    {
      "metadata": {
        "_uuid": "e12eb84c9c6defa600b45539d534f88f6bac0809"
      },
      "cell_type": "markdown",
      "source": "  **IMPORTING LIBRARIES**"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#import libraries\nimport nltk\nfrom nltk.corpus import stopwords#for stopwords\nfrom nltk.tokenize import word_tokenize#for tokenizing words\nfrom nltk.tokenize import sent_tokenize#sentence tokenizer\nfrom nltk import ne_chunk, pos_tag\nimport pandas as pd\nimport numpy as np\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd65e2700aabb5161bb9efde36be60443ded3317",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#load data\ntrain_data=pd.read_csv(\"../input/train.csv\")\n#test_data=pd.read_csv(\"../input/test.csv\")\nx=train_data.iloc[:,1].values\ncomment=np.array2string(x)\nprint(comment)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "c5da9af4c5bb3023daad451ee0ad12423abb944f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#removing unncessary punction marks from text\nfrom nltk.tokenize import RegexpTokenizer\ntokenizer=RegexpTokenizer(r'\\w+')\ncomment1=tokenizer.tokenize(comment)\nprint(comment1)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "adb6274a3a179557f5e458f72f77a121ccd11526",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#---------------------TEXT PRE PROCESSING-------------------------------------\n\n#STEP 1:NOISE REMOVAL-USING STOPWORDS\n#removing unwanted words for analysing-tokenizing and then applying stopwords\ncomment_1=\" \".join(str(e) for e in comment1)\nword=word_tokenize(comment_1)\nfiltered_comment=[]\nstop_words=set(stopwords.words(\"english\"))\n#print(stop_words)\nfor w in word:\n    if w not in stop_words:\n       filtered_comment.append(w)    \nprint(len(filtered_comment))\ncomment2= \" \".join(str(e) for e in filtered_comment) #converting list to string\nprint(comment2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2323d92e1b0c7a3da0e6b21b145eead4b7d36aa5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sent_tokenizer=sent_tokenize(comment)\nprint(sent_tokenizer)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#----------------TEXT TO FEATURES---------------------------------------------\n#STEP 2:POS TAGGING\n\nprint(pos_tag(word))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "59ebd164b4e51fca2628dfdfb23b030c1fffd428",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#analsing name entities:PERSON,ORGANIZATION AND LOCATION MENTIONED\ndef entities():\n    return ne_chunk(pos_tag(word))\ntree=entities()\ntree.pprint()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fbed2c6a405984e54587a0488207113098381294"
      },
      "cell_type": "code",
      "source": "# from sklearn.feature_extraction.text import CountVectorizer\n# from sklearn.ensemble import RandomForestClassifier\n# #creating bag of words\n# vectorizer=CountVectorizer()\n# #fitting the model\n# features=vectorizer.fit_transform(x)\n# #print(filtered_comment)\n# #print(features)\n# features1=features.toarray()\n# #print(features)\n# #training the model\n# forest=RandomForestClassifier(n_estimators=100)\n# forest=forest.fit(features1,train_data[\"toxic\"])\n# test_output=[]\n# #Format test data\n# test_data=pd.read_csv(\"../input/test.csv\")\n# y=test_data.iloc[:,1].values\n# comment=np.array2string(y)\n# print(comment)\n",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MemoryError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-9b355945edce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#print(filtered_comment)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfeatures1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#print(features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMemoryError\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}